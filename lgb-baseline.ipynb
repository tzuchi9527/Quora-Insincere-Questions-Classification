{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport string\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['embeddings', 'sample_submission.csv', 'test.csv', 'train.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import model_selection, preprocessing, metrics, ensemble, naive_bayes, linear_model\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.metrics import f1_score\nimport lightgbm as lgb",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "42f2810391a33f92e7d53dc3bb50fc039734904b"
      },
      "cell_type": "code",
      "source": "train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\nprint(\"Train shape : \", train_df.shape)\nprint(\"Test shape : \", test_df.shape)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train shape :  (1306122, 3)\nTest shape :  (375806, 2)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4d518db1fc0a5be0a9421ab6054a0772e4a8315b"
      },
      "cell_type": "code",
      "source": "train_df.head()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "                    qid  ...   target\n0  00002165364db923c7e6  ...        0\n1  000032939017120e6e44  ...        0\n2  0000412ca6e4628ce2cf  ...        0\n3  000042bf85aa498cd78e  ...        0\n4  0000455dfa3e01eae3af  ...        0\n\n[5 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>question_text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00002165364db923c7e6</td>\n      <td>How did Quebec nationalists see their province...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000032939017120e6e44</td>\n      <td>Do you have an adopted dog, how would you enco...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0000412ca6e4628ce2cf</td>\n      <td>Why does velocity affect time? Does velocity a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000042bf85aa498cd78e</td>\n      <td>How did Otto von Guericke used the Magdeburg h...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0000455dfa3e01eae3af</td>\n      <td>Can I convert montra helicon D to a mountain b...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "192ed21ec4566f62a14eb8488827bc52cb2dae44"
      },
      "cell_type": "code",
      "source": "from nltk.corpus import stopwords\nSTOPWORDS = set(stopwords.words('english'))\n\n## Number of words in the text ##\ntrain_df[\"num_words\"] = train_df[\"question_text\"].apply(lambda x: len(str(x).split()))\ntest_df[\"num_words\"] = test_df[\"question_text\"].apply(lambda x: len(str(x).split()))\n\n## Number of unique words in the text ##\ntrain_df[\"num_unique_words\"] = train_df[\"question_text\"].apply(lambda x: len(set(str(x).split())))\ntest_df[\"num_unique_words\"] = test_df[\"question_text\"].apply(lambda x: len(set(str(x).split())))\n\n## Number of characters in the text ##\ntrain_df[\"num_chars\"] = train_df[\"question_text\"].apply(lambda x: len(str(x)))\ntest_df[\"num_chars\"] = test_df[\"question_text\"].apply(lambda x: len(str(x)))\n\n## Number of stopwords in the text ##\ntrain_df[\"num_stopwords\"] = train_df[\"question_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\ntest_df[\"num_stopwords\"] = test_df[\"question_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n\n## Number of punctuations in the text ##\ntrain_df[\"num_punctuations\"] =train_df['question_text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\ntest_df[\"num_punctuations\"] =test_df['question_text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n\n## Number of title case words in the text ##\ntrain_df[\"num_words_upper\"] = train_df[\"question_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\ntest_df[\"num_words_upper\"] = test_df[\"question_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n\n## Number of title case words in the text ##\ntrain_df[\"num_words_title\"] = train_df[\"question_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\ntest_df[\"num_words_title\"] = test_df[\"question_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n\n## Average length of the words in the text ##\ntrain_df[\"mean_word_len\"] = train_df[\"question_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\ntest_df[\"mean_word_len\"] = test_df[\"question_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f14e88f320eb29be3eaf87a8de21d53364c32ccb"
      },
      "cell_type": "code",
      "source": "## Truncate some extreme values for better visuals ##\ntrain_df['num_words'].loc[train_df['num_words']>60] = 60 #truncation for better visuals\ntrain_df['num_punctuations'].loc[train_df['num_punctuations']>10] = 10 #truncation for better visuals\ntrain_df['num_chars'].loc[train_df['num_chars']>350] = 350 #truncation for better visuals",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  self._setitem_with_indexer(indexer, value)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "66b9c968ac6dd54399c36b3f60436e11adb68781"
      },
      "cell_type": "code",
      "source": "train_text = train_df['question_text']\ntest_text = test_df['question_text']\nall_text = pd.concat([train_text, test_text])\n\nword_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    stop_words='english',\n    ngram_range=(1, 1),\n    max_features=5000)\nword_vectorizer.fit(all_text)\ntrain_tfidf = word_vectorizer.transform(train_text)\ntest_tfidf = word_vectorizer.transform(test_text)",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "79ec21b2185f9a4cd05fbc9f62554d0d8648612d"
      },
      "cell_type": "code",
      "source": "eng_features = ['num_words', 'num_unique_words', 'num_chars', \n                'num_stopwords', 'num_punctuations', 'num_words_upper', \n                'num_words_title', 'mean_word_len']\ntrain_ = train_df[eng_features]",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3019f4584d78409db43dee95f385985d2d88ac51"
      },
      "cell_type": "code",
      "source": "from scipy.sparse import hstack, csr_matrix\ntrain_ = hstack((csr_matrix(train_), train_tfidf))\nprint(train_.shape)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(1306122, 5008)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5bf14812e2f33c56097ec12fb177b441e5e88803"
      },
      "cell_type": "code",
      "source": "test_ = test_df[eng_features]\ntest_ = hstack((csr_matrix(test_), test_tfidf))\nprint(test_.shape)",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(375806, 5008)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d38a44aa605814d2d3dbef2b5122f39836534379"
      },
      "cell_type": "code",
      "source": "train_y = train_df[\"target\"].values\n\nx_train, x_val, y_train, y_val = model_selection.train_test_split(train_, train_y, test_size=0.2, random_state=42)\n\nprint(x_train.shape, x_val.shape)",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(1044897, 5008) (261225, 5008)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "48c07d22d3d9fbae7ac0528aaabf2f3943771b32"
      },
      "cell_type": "code",
      "source": "%%time\nfrom sklearn.metrics import f1_score\n\ndef lgb_f1_score(y_hat, data):\n    y_true = data.get_label()\n    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n    return 'f1', f1_score(y_true, y_hat), True\n\nparams = {'application': 'binary',\n          'metric': 'binary_logloss',\n          'learning_rate': 0.05,   \n          'max_depth': 9,\n          'num_leaves': 100,\n          'verbosity': -1,\n          'data_random_seed': 3,\n          'bagging_fraction': 0.8,\n          'feature_fraction': 0.4,\n          'nthread': 16,\n          'lambda_l1': 1,\n          'lambda_l2': 1,\n          'num_rounds': 2700,\n          'verbose_eval': 100}\n\nd_train = lgb.Dataset(x_train, label=y_train)\nd_valid = lgb.Dataset(x_val, label=y_val)\nprint('Train LGB')\nnum_rounds = params.pop('num_rounds')\nverbose_eval = params.pop('verbose_eval')\nmodel = lgb.train(params,\n                  train_set=d_train,\n                  num_boost_round=num_rounds,\n                  valid_sets=[d_train, d_valid],\n                  verbose_eval=verbose_eval,\n                  valid_names=['train', 'val'],\n                  feval=lgb_f1_score)\nprint('Predict')\npred_test_va = model.predict(x_val)",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train LGB\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "[100]\ttrain's binary_logloss: 0.155827\ttrain's f1: 0.301909\tval's binary_logloss: 0.156128\tval's f1: 0.282632\n[200]\ttrain's binary_logloss: 0.146923\ttrain's f1: 0.37326\tval's binary_logloss: 0.148458\tval's f1: 0.35076\n[300]\ttrain's binary_logloss: 0.141664\ttrain's f1: 0.406796\tval's binary_logloss: 0.144095\tval's f1: 0.379636\n[400]\ttrain's binary_logloss: 0.137879\ttrain's f1: 0.430888\tval's binary_logloss: 0.14115\tval's f1: 0.399964\n[500]\ttrain's binary_logloss: 0.135007\ttrain's f1: 0.448233\tval's binary_logloss: 0.139036\tval's f1: 0.41228\n[600]\ttrain's binary_logloss: 0.132656\ttrain's f1: 0.461935\tval's binary_logloss: 0.137356\tval's f1: 0.42436\n[700]\ttrain's binary_logloss: 0.130644\ttrain's f1: 0.473417\tval's binary_logloss: 0.136005\tval's f1: 0.432314\n[800]\ttrain's binary_logloss: 0.128887\ttrain's f1: 0.483113\tval's binary_logloss: 0.134843\tval's f1: 0.439383\n[900]\ttrain's binary_logloss: 0.127356\ttrain's f1: 0.491789\tval's binary_logloss: 0.133882\tval's f1: 0.444655\n[1000]\ttrain's binary_logloss: 0.126024\ttrain's f1: 0.498736\tval's binary_logloss: 0.133056\tval's f1: 0.448665\n[1100]\ttrain's binary_logloss: 0.124732\ttrain's f1: 0.504989\tval's binary_logloss: 0.132288\tval's f1: 0.454801\n[1200]\ttrain's binary_logloss: 0.123585\ttrain's f1: 0.510873\tval's binary_logloss: 0.131676\tval's f1: 0.458356\n[1300]\ttrain's binary_logloss: 0.122471\ttrain's f1: 0.516413\tval's binary_logloss: 0.131101\tval's f1: 0.461603\n[1400]\ttrain's binary_logloss: 0.121483\ttrain's f1: 0.521594\tval's binary_logloss: 0.130588\tval's f1: 0.463662\n[1500]\ttrain's binary_logloss: 0.120523\ttrain's f1: 0.526793\tval's binary_logloss: 0.130088\tval's f1: 0.467898\n[1600]\ttrain's binary_logloss: 0.119647\ttrain's f1: 0.531098\tval's binary_logloss: 0.129672\tval's f1: 0.470819\n[1700]\ttrain's binary_logloss: 0.118814\ttrain's f1: 0.535526\tval's binary_logloss: 0.129287\tval's f1: 0.473418\n[1800]\ttrain's binary_logloss: 0.11802\ttrain's f1: 0.539509\tval's binary_logloss: 0.128929\tval's f1: 0.476139\n[1900]\ttrain's binary_logloss: 0.117247\ttrain's f1: 0.543241\tval's binary_logloss: 0.128593\tval's f1: 0.478694\n[2000]\ttrain's binary_logloss: 0.116542\ttrain's f1: 0.546901\tval's binary_logloss: 0.128288\tval's f1: 0.480996\n[2100]\ttrain's binary_logloss: 0.115848\ttrain's f1: 0.550147\tval's binary_logloss: 0.127997\tval's f1: 0.481958\n[2200]\ttrain's binary_logloss: 0.115228\ttrain's f1: 0.553225\tval's binary_logloss: 0.127728\tval's f1: 0.483452\n[2300]\ttrain's binary_logloss: 0.114608\ttrain's f1: 0.556168\tval's binary_logloss: 0.127462\tval's f1: 0.485129\n[2400]\ttrain's binary_logloss: 0.113983\ttrain's f1: 0.558556\tval's binary_logloss: 0.127232\tval's f1: 0.486049\n[2500]\ttrain's binary_logloss: 0.113422\ttrain's f1: 0.561209\tval's binary_logloss: 0.127041\tval's f1: 0.486922\n[2600]\ttrain's binary_logloss: 0.112853\ttrain's f1: 0.56459\tval's binary_logloss: 0.126843\tval's f1: 0.488014\n[2700]\ttrain's binary_logloss: 0.11229\ttrain's f1: 0.567582\tval's binary_logloss: 0.126647\tval's f1: 0.489992\nPredict\nCPU times: user 57min 5s, sys: 2min 1s, total: 59min 6s\nWall time: 27min 42s\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "948ba1b23547e29f186cabf4b4c8446dfaae22a2"
      },
      "cell_type": "code",
      "source": "%%time\nbest_threshold = 0.01\nbest_score = 0.0\nfor threshold in range(1, 100):\n    threshold = threshold / 100\n    score = f1_score(y_val, pred_test_va > threshold)\n    if score > best_score:\n        best_threshold = threshold\n        best_score = score\nprint(0.5, f1_score(y_val, pred_test_va > 0.5))\nprint(best_threshold, best_score)",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0.5 0.48999186330349886\n0.25 0.5897412782836021\nCPU times: user 4.2 s, sys: 0 ns, total: 4.2 s\nWall time: 4.2 s\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1ef6fb80500b0960ab4c8621a017f36469f7ea5d"
      },
      "cell_type": "code",
      "source": "%%time\npred_test_y = model.predict(test_)",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:469: UserWarning: Converting data to scipy sparse matrix.\n  warnings.warn('Converting data to scipy sparse matrix.')\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f9f4ed1e2371bd37ad178a52d0bc6da1fce6caf0"
      },
      "cell_type": "code",
      "source": "submit_df = pd.DataFrame({\"qid\": test_df[\"qid\"], \"prediction\": (pred_test_y > best_threshold).astype(np.int)})\nsubmit_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3996c8ccc6c112b0124c2c59db539cc5b8903819"
      },
      "cell_type": "code",
      "source": "submit_df['prediction'].value_counts()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1d96f9f9c4d1337858253ae520906495d4489447"
      },
      "cell_type": "code",
      "source": "submit_df.to_csv(\"submission.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2780967cbdea21216f53293c98c979c4f258da31"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}